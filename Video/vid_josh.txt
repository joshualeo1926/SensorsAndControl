SURF feature detection - SURFdetection.mkv
to detect the marker in the environment we sample a RGB image from the fetch's RGB-D camera and run a SURF feature detection on it, once we have a certain amount of matched points giving us a high confidence we have found the marker we estimate the geometric transform from the target image to the matched image.

location the guider - maker_track.mkv (optional to use here or later - aux_2.mkv)
Using this affine transform we are able to get the transformed four corners of the marker in the environment and find the center of it in pixel co-ordinates, which we then save for later to sample the distance from the RGB-D camera data. getting the horizontal (x) co-oridinates of the marker also allows us to get a error value that is proportinal to the difference between the fetchs'/cameras orientation and the markers, this error value will serve as the input to our PID that controlls the fetchs' angular velocity.

RGB-D - aux_1.mkv
using the pixel co-ordinated we found from the image tracking in the previouse step, we sample the RGB-D data to get the distance from the fetch to the center of the marker/guider, this distance is the error that will be used as the input to the PID that controlls the fetchs' linear velocity.

PID controll - ang_pid.mkv - dst_pid.mkv
Using a Propotional, integral and differential (PID) controller, and the error values we previousely determined we are able to have a closed loop control system that send linear or angular velocities to the fetch robot to reduce these error values in smooth and responsive fashion, that is also able to be tweaked by adjusting the Propotional, integral and differential cosntants.
